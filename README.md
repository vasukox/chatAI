# ğŸ¤– Ollama Chat AI

Un chatbot interactivo de lÃ­nea de comandos (CLI) construido con Python que utiliza [Ollama](https://ollama.ai/) para interactuar con modelos de IA de forma local.

## âœ¨ CaracterÃ­sticas

- **Interfaz CLI interactiva**: Conversaciones fluidas directamente desde tu terminal
- **Arquitectura limpia**: DiseÃ±o modular con capas de dominio, servicios e interfaz
- **GestiÃ³n de conversaciÃ³n**: Mantiene el contexto del chat con historial de mensajes
- **Soporte multimodelo**: Compatible con diferentes modelos de Ollama (Mistral, Llama2, etc.)
- **Comandos integrados**: Controles para limpiar historial, ver estadÃ­sticas y mÃ¡s
- **Multiidioma**: ConfiguraciÃ³n de idioma personalizable

## ğŸ“‹ Requisitos Previos

Antes de comenzar, asegÃºrate de tener instalado:

- **Python 3.8+**
- **Ollama**: Instala Ollama desde [ollama.ai](https://ollama.ai/)

### InstalaciÃ³n de Ollama

#### Windows
```bash
# Descarga el instalador desde https://ollama.ai/download
```

#### macOS
```bash
brew install ollama
```

#### Linux
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

Una vez instalado, inicia el servicio de Ollama:
```bash
ollama serve
```

## ğŸš€ InstalaciÃ³n

1. **Clona el repositorio**
```bash
git clone https://github.com/vasukox/chatAI.git
cd chatAI
```

2. **Crea un entorno virtual** (recomendado)
```bash
python -m venv venv

# Windows
venv\Scripts\activate

# macOS/Linux
source venv/bin/activate
```

3. **Instala las dependencias**
```bash
pip install -r requirements.txt
```

4. **Descarga un modelo de Ollama** (si no lo tienes)
```bash
# Mistral (recomendado, usado por defecto)
ollama pull mistral

# O Llama2
ollama pull llama2
```

## ğŸ’» Uso

### Iniciar el chatbot

```bash
python main.py
```

### Comandos disponibles

Una vez iniciado el chatbot, puedes usar los siguientes comandos:

| Comando | DescripciÃ³n |
|---------|-------------|
| `salir` o `exit` | Termina la sesiÃ³n del chat |
| `limpiar` o `clear` | Limpia el historial de conversaciÃ³n |
| `historial` o `history` | Muestra el nÃºmero de mensajes en la conversaciÃ³n |

### Ejemplo de uso

```
============================================================
ğŸ¤– CHATBOT CON OLLAMA
============================================================
Modelo: mistral
Idioma: ES

Comandos disponibles:
  - 'salir' o 'exit': Termina el chat
  - 'limpiar' o 'clear': Limpia el historial
  - 'historial': Muestra el nÃºmero de mensajes
============================================================

Verificando disponibilidad del modelo...
âœ“ Modelo mistral listo para usar.

Puedes empezar a chatear...

TÃº: Hola, Â¿cÃ³mo estÃ¡s?

ğŸ¤– Asistente: Â¡Hola! Estoy bien, gracias por preguntar. Soy un asistente de IA y estoy aquÃ­ para ayudarte. Â¿En quÃ© puedo ayudarte hoy?

TÃº: salir

ğŸ‘‹ Â¡Hasta luego!
```

## ğŸ“ Estructura del Proyecto

```
chatAI/
â”œâ”€â”€ main.py                      # Punto de entrada de la aplicaciÃ³n
â”œâ”€â”€ requirements.txt             # Dependencias del proyecto
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ domain/                  # Capa de dominio
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ models.py           # Modelos de datos (Message, Conversation)
â”‚   â”œâ”€â”€ services/               # Capa de servicios
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ ollama_service.py  # Servicio de integraciÃ³n con Ollama
â”‚   â””â”€â”€ interface/              # Capa de interfaz
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ cli.py              # Interfaz de lÃ­nea de comandos
â””â”€â”€ README.md
```

### DescripciÃ³n de las capas

- **Domain**: Contiene las entidades y modelos de datos del negocio
  - `Message`: Representa un mensaje en la conversaciÃ³n
  - `Conversation`: Gestiona el historial de mensajes

- **Services**: Implementa la lÃ³gica de negocio y la integraciÃ³n con servicios externos
  - `OllamaService`: Maneja la comunicaciÃ³n con la API de Ollama

- **Interface**: Capa de presentaciÃ³n para interactuar con el usuario
  - `ChatbotCLI`: Interfaz de lÃ­nea de comandos interactiva

## ğŸ”§ ConfiguraciÃ³n

### Cambiar el modelo de IA

Edita [main.py](main.py) para cambiar el modelo:

```python
def main():
    # Cambiar 'mistral' por otro modelo disponible
    chatbot = ChatbotCLI(model_name='llama2', language='es')
    chatbot.run()
```

### Modelos populares disponibles en Ollama

- `mistral` - Modelo potente y rÃ¡pido (recomendado)
- `llama2` - Modelo de Meta AI
- `codellama` - Especializado en cÃ³digo
- `phi` - Modelo ligero de Microsoft
- `gemma` - Modelo de Google

Para ver todos los modelos disponibles:
```bash
ollama list
```

## ğŸ› ï¸ Desarrollo

### Requisitos para desarrollo

```bash
pip install -r requirements.txt
```

### Ejecutar en modo desarrollo

```bash
python main.py
```

## ğŸ¤ Contribuir

Las contribuciones son bienvenidas. Si deseas contribuir:

1. Haz un Fork del proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“ Licencia

Este proyecto es de cÃ³digo abierto y estÃ¡ disponible bajo la licencia MIT.

## ğŸ™ Agradecimientos

- [Ollama](https://ollama.ai/) - Por proporcionar una forma sencilla de ejecutar LLMs localmente
- [Mistral AI](https://mistral.ai/) - Por el excelente modelo Mistral
- [Meta AI](https://ai.meta.com/) - Por Llama2

## ğŸ“§ Contacto

Si tienes preguntas o sugerencias, no dudes en abrir un issue en el repositorio.

---

**Desarrollado con â¤ï¸ usando Python y Ollama**
